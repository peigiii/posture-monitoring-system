"""
Dataset Evaluation Script
Evaluate posture detection algorithm performance on dataset

Usage:
    python evaluation/evaluate_dataset.py
"""

import cv2
import os
import math as m
import mediapipe as mp
from pathlib import Path
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
import numpy as np

# MediaPipe åˆå§‹åŒ–
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(static_image_mode=True)

# é˜ˆå€¼è®¾ç½®ï¼ˆä¸ä¸»ç¨‹åºä¿æŒä¸€è‡´ï¼‰
DEFAULT_NECK_THRESHOLD = 40
DEFAULT_TORSO_THRESHOLD = 15
ALIGNMENT_THRESHOLD = 100  # ä¾§é¢å¯¹é½é˜ˆå€¼

# SCIæ‚£è€…ä¸“ç”¨é˜ˆå€¼é…ç½®ç³»ç»Ÿï¼ˆä¸ç½‘ç«™ä¿æŒä¸€è‡´ï¼‰
SCI_THRESHOLDS = {
    'standard': {
        'neck': 40,
        'torso': 15,
        'shoulder': 30,
        'hip': 25,
        'head': 25,
        'spinal': 20,  # è„ŠæŸ±å¼¯æ›²åº¦é˜ˆå€¼
        'weighted_score_threshold': 0.70
    },
    'sciRelaxed': {
        'neck': 50,
        'torso': 25,
        'shoulder': 40,
        'hip': 35,
        'head': 35,
        'spinal': 25,
        'weighted_score_threshold': 0.60
    },
    'sciStrict': {
        'neck': 45,
        'torso': 20,
        'shoulder': 35,
        'hip': 30,
        'head': 30,
        'spinal': 22,
        'weighted_score_threshold': 0.65
    }
}

# å½“å‰ä½¿ç”¨çš„é˜ˆå€¼æ¨¡å¼
CURRENT_THRESHOLD_MODE = 'standard'  # 'standard' | 'sciRelaxed' | 'sciStrict'

# ä½¿ç”¨åŠ æƒè¯„åˆ†è€Œä¸æ˜¯"å…¨éƒ¨é€šè¿‡"
USE_WEIGHTED_SCORING = True      # ä½¿ç”¨åŠ æƒè¯„åˆ†ï¼ˆæ›´åˆç†ï¼‰

# å…¼å®¹æ—§ä»£ç çš„é˜ˆå€¼ï¼ˆä½¿ç”¨æ ‡å‡†æ¨¡å¼ï¼‰
SHOULDER_HEIGHT_THRESHOLD = SCI_THRESHOLDS[CURRENT_THRESHOLD_MODE]['shoulder']
HIP_HEIGHT_THRESHOLD = SCI_THRESHOLDS[CURRENT_THRESHOLD_MODE]['hip']
HEAD_TILT_THRESHOLD = SCI_THRESHOLDS[CURRENT_THRESHOLD_MODE]['head']
WEIGHTED_SCORE_THRESHOLD = SCI_THRESHOLDS[CURRENT_THRESHOLD_MODE]['weighted_score_threshold']

def findDistance(x1, y1, x2, y2):
    """è®¡ç®—ä¸¤ç‚¹è·ç¦»"""
    return m.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)

def findAngle(x1, y1, x2, y2):
    """è®¡ç®—è§’åº¦ï¼ˆä¸ä¸»ç¨‹åºä¿æŒä¸€è‡´ï¼‰"""
    try:
        denominator = m.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1
        if abs(denominator) < 0.0001:
            return 0
        numerator = (y2 - y1) * (-y1)
        ratio = numerator / denominator
        clamped_ratio = max(-1, min(1, ratio))
        theta = m.acos(clamped_ratio)
        return int(180 / m.pi) * theta
    except:
        return 0

def calculate_progressive_score(value, threshold, weight):
    """
    ä¼˜åŒ–çš„æ¸è¿›å¼æ‰£åˆ†å‡½æ•°ï¼ˆä½¿ç”¨æ›´å¹³æ»‘çš„æ›²çº¿ï¼‰
    ä¸ç½‘ç«™ç®—æ³•ä¿æŒä¸€è‡´
    """
    if value < threshold:
        # åœ¨é˜ˆå€¼å†…ï¼šå®Œå…¨å¾—åˆ†ï¼Œä½†æ¥è¿‘é˜ˆå€¼æ—¶ç¨å¾®æ‰£åˆ†
        ratio = value / threshold
        bonus = 1.0 if ratio < 0.7 else 1.0 - ((ratio - 0.7) / 0.3) * 0.1
        return weight * bonus
    else:
        # è¶…è¿‡é˜ˆå€¼ï¼šæ¸è¿›å¼æ‰£åˆ†ï¼ˆä½¿ç”¨å¹³æ–¹æ ¹è¡°å‡ï¼‰
        excess = value - threshold
        excess_ratio = excess / threshold
        penalty_ratio = min(m.sqrt(excess_ratio * 2), 1.0)
        return weight * (1 - penalty_ratio)

def calculate_angle_progressive_score(value, threshold, weight):
    """
    è§’åº¦æ¨¡å¼çš„æ¸è¿›å¼æ‰£åˆ†å‡½æ•°
    """
    if value < threshold:
        ratio = value / threshold
        bonus = 1.0 if ratio < 0.75 else 1.0 - ((ratio - 0.75) / 0.25) * 0.15
        return weight * bonus
    else:
        excess = value - threshold
        excess_ratio = excess / threshold
        penalty_ratio = min(m.sqrt(excess_ratio * 1.5), 1.0)
        return weight * (1 - penalty_ratio)

def calculate_posture_score_front(metrics, thresholds, is_sci_mode=False):
    """
    æ”¹è¿›çš„åŠ æƒè¯„åˆ†ç³»ç»Ÿï¼ˆæ­£é¢æ¨¡å¼ï¼‰
    ä¸ç½‘ç«™ç®—æ³•ä¿æŒä¸€è‡´
    """
    score = 0.0
    breakdown = {}
    
    # æ ¹æ®æ¨¡å¼è°ƒæ•´æƒé‡
    if is_sci_mode:
        weights = {
            'shoulder': 0.30,
            'hip': 0.30,
            'head': 0.25,
            'spinal': 0.15
        }
    else:
        weights = {
            'shoulder': 0.35,
            'hip': 0.30,
            'head': 0.20,
            'spinal': 0.15
        }
    
    # å¦‚æœæ²¡æœ‰è„ŠæŸ±æ•°æ®ï¼Œé‡æ–°åˆ†é…æƒé‡
    has_spinal = 'spinal_curvature' in metrics and metrics['spinal_curvature'] is not None
    if not has_spinal:
        total = weights['shoulder'] + weights['hip'] + weights['head']
        weights['shoulder'] = weights['shoulder'] / total
        weights['hip'] = weights['hip'] / total
        weights['head'] = weights['head'] / total
        weights['spinal'] = 0
    
    # è®¡ç®—å„é¡¹å¾—åˆ†
    breakdown['shoulder'] = calculate_progressive_score(
        metrics['shoulder_height_diff'], thresholds['shoulder'], weights['shoulder']
    )
    breakdown['hip'] = calculate_progressive_score(
        metrics['hip_height_diff'], thresholds['hip'], weights['hip']
    )
    breakdown['head'] = calculate_progressive_score(
        metrics['head_tilt'], thresholds['head'], weights['head']
    )
    
    if has_spinal and thresholds.get('spinal'):
        breakdown['spinal'] = calculate_progressive_score(
            metrics['spinal_curvature'], thresholds['spinal'], weights['spinal']
        )
    else:
        breakdown['spinal'] = 0
    
    score = sum(breakdown.values())
    threshold_config = SCI_THRESHOLDS[CURRENT_THRESHOLD_MODE]
    score_threshold = threshold_config['weighted_score_threshold']
    
    return {
        'score': score,
        'is_good': score >= score_threshold,
        'breakdown': breakdown,
        'percentage': int(score * 100)
    }

def calculate_posture_score_side(metrics, thresholds, is_sci_mode=False):
    """
    æ”¹è¿›çš„åŠ æƒè¯„åˆ†ç³»ç»Ÿï¼ˆä¾§é¢æ¨¡å¼ï¼‰
    ä¸ç½‘ç«™ç®—æ³•ä¿æŒä¸€è‡´
    """
    score = 0.0
    breakdown = {}
    
    # æƒé‡é…ç½®
    if is_sci_mode:
        weights = {'neck': 0.45, 'torso': 0.55}
    else:
        weights = {'neck': 0.50, 'torso': 0.50}
    
    # è®¡ç®—å¾—åˆ†
    breakdown['neck'] = calculate_angle_progressive_score(
        metrics['neck_angle'], thresholds['neck'], weights['neck']
    )
    breakdown['torso'] = calculate_angle_progressive_score(
        metrics['torso_angle'], thresholds['torso'], weights['torso']
    )
    
    score = sum(breakdown.values())
    threshold_config = SCI_THRESHOLDS[CURRENT_THRESHOLD_MODE]
    score_threshold = threshold_config['weighted_score_threshold']
    
    return {
        'score': score,
        'is_good': score >= score_threshold,
        'breakdown': breakdown,
        'percentage': int(score * 100)
    }

def analyze_image(image_path, use_enhanced_detection=True, detect_view=False, threshold_mode=None):
    """
    åˆ†æå•å¼ å›¾åƒï¼Œè¿”å›å§¿åŠ¿æ£€æµ‹ç»“æœï¼ˆå¢å¼ºç‰ˆï¼šåŒ…å«å¤šä¸ªæ£€æµ‹æŒ‡æ ‡ï¼‰
    
    Args:
        image_path: å›¾åƒè·¯å¾„
        use_enhanced_detection: æ˜¯å¦ä½¿ç”¨å¢å¼ºæ£€æµ‹ï¼ˆå¤šæŒ‡æ ‡ï¼‰
    
    Returns:
        dict: {
            'neck_angle': float,
            'torso_angle': float,
            'shoulder_height_diff': float,
            'hip_height_diff': float,
            'head_tilt': float,
            'is_aligned': bool,
            'predicted_label': str,  # 'good' or 'bad'
            'predicted_label_basic': str,  # åŸºç¡€ç‰ˆæœ¬ï¼ˆåªè€ƒè™‘ä¸¤ä¸ªè§’åº¦ï¼‰
            'landmarks_detected': bool,
            'issues': list  # æ£€æµ‹åˆ°çš„é—®é¢˜åˆ—è¡¨
        }
    """
    # è¯»å–å›¾åƒ
    image = cv2.imread(str(image_path))
    if image is None:
        return None
    
    h, w = image.shape[:2]
    
    # è½¬æ¢ä¸º RGB
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # å¤„ç†å›¾åƒ
    results = pose.process(image_rgb)
    
    if results.pose_landmarks is None:
        return {
            'neck_angle': 0,
            'torso_angle': 0,
            'shoulder_height_diff': 0,
            'hip_height_diff': 0,
            'head_tilt': 0,
            'is_aligned': False,
            'predicted_label': 'bad',
            'predicted_label_basic': 'bad',
            'landmarks_detected': False,
            'issues': ['landmarks_not_detected']
        }
    
    lm = results.pose_landmarks
    lmPose = mp_pose.PoseLandmark
    
    # è·å–å…³é”®ç‚¹åæ ‡
    try:
        l_shldr_x = int(lm.landmark[lmPose.LEFT_SHOULDER].x * w)
        l_shldr_y = int(lm.landmark[lmPose.LEFT_SHOULDER].y * h)
        r_shldr_x = int(lm.landmark[lmPose.RIGHT_SHOULDER].x * w)
        r_shldr_y = int(lm.landmark[lmPose.RIGHT_SHOULDER].y * h)
        l_ear_x = int(lm.landmark[lmPose.LEFT_EAR].x * w)
        l_ear_y = int(lm.landmark[lmPose.LEFT_EAR].y * h)
        r_ear_x = int(lm.landmark[lmPose.RIGHT_EAR].x * w)
        r_ear_y = int(lm.landmark[lmPose.RIGHT_EAR].y * h)
        l_hip_x = int(lm.landmark[lmPose.LEFT_HIP].x * w)
        l_hip_y = int(lm.landmark[lmPose.LEFT_HIP].y * h)
        r_hip_x = int(lm.landmark[lmPose.RIGHT_HIP].x * w)
        r_hip_y = int(lm.landmark[lmPose.RIGHT_HIP].y * h)
    except:
        return {
            'neck_angle': 0,
            'torso_angle': 0,
            'shoulder_height_diff': 0,
            'hip_height_diff': 0,
            'head_tilt': 0,
            'is_aligned': False,
            'predicted_label': 'bad',
            'predicted_label_basic': 'bad',
            'landmarks_detected': False,
            'issues': ['landmarks_error']
        }
    
    # è®¡ç®—å¯¹é½è·ç¦»
    offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)
    is_aligned = offset < ALIGNMENT_THRESHOLD  # True=ä¾§é¢å¯¹é½, False=æ­£é¢å¯¹é½
    
    # è®¡ç®—è§’åº¦ï¼ˆåŸºç¡€æ£€æµ‹ï¼‰
    try:
        neck_angle = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)
        torso_angle = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)
    except:
        neck_angle = 0
        torso_angle = 0
    
    # åŸºç¡€åˆ¤å®šï¼ˆåªè€ƒè™‘ä¸¤ä¸ªè§’åº¦ï¼‰
    is_good_basic = neck_angle < DEFAULT_NECK_THRESHOLD and torso_angle < DEFAULT_TORSO_THRESHOLD
    
    # è·å–å½“å‰é˜ˆå€¼é…ç½®
    if threshold_mode is None:
        threshold_mode = CURRENT_THRESHOLD_MODE
    thresholds = SCI_THRESHOLDS.get(threshold_mode, SCI_THRESHOLDS['standard'])
    is_sci_mode = threshold_mode != 'standard'
    
    # å¢å¼ºæ£€æµ‹ï¼ˆå¤šæŒ‡æ ‡ï¼‰
    shoulder_height_diff = abs(l_shldr_y - r_shldr_y)
    hip_height_diff = abs(l_hip_y - r_hip_y)
    head_tilt = abs(l_ear_y - r_ear_y)
    
    # è„ŠæŸ±å¼¯æ›²åº¦æ£€æµ‹ï¼ˆæ–°å¢ï¼‰
    # æ³¨æ„ï¼šå¯¹äºä¾§è§†å›¾ï¼Œè„ŠæŸ±å¼¯æ›²åº¦æ£€æµ‹å¯èƒ½ä¸å‡†ç¡®ï¼Œå› ä¸ºä¾§è§†å›¾ä¸»è¦çœ‹å‰åå€¾æ–œ
    # åªåœ¨æ­£é¢å¯¹é½æ—¶ä½¿ç”¨è„ŠæŸ±å¼¯æ›²åº¦æ£€æµ‹
    spinal_curvature = 0
    spinal_direction = None
    use_spinal_detection = not is_aligned  # æ­£é¢å¯¹é½æ—¶ä½¿ç”¨ï¼ˆis_aligned=Falseè¡¨ç¤ºæ­£é¢ï¼‰
    
    if use_spinal_detection:
        try:
            shoulder_mid_y = (l_shldr_y + r_shldr_y) / 2
            hip_mid_y = (l_hip_y + r_hip_y) / 2
            spinal_curvature = abs(shoulder_mid_y - hip_mid_y)
            spinal_direction = 'forward' if shoulder_mid_y > hip_mid_y else 'backward'
        except:
            pass
    
    # ç»¼åˆåˆ¤å®šï¼ˆå¢å¼ºç‰ˆï¼‰
    # é‡è¦ï¼šå¯¹äºä¾§è§†å›¾ï¼Œä¸»è¦æ£€æµ‹è§’åº¦ï¼›å¯¹äºæ­£è§†å›¾ï¼Œæ£€æµ‹å¯¹ç§°æ€§
    issues = []
    
    # è§’åº¦æ£€æµ‹ï¼ˆä¾§è§†å›¾å’Œæ­£è§†å›¾éƒ½é€‚ç”¨ï¼‰
    if neck_angle >= thresholds['neck']:
        issues.append('neck_forward')
    if torso_angle >= thresholds['torso']:
        issues.append('torso_forward')
    
    # å¯¹ç§°æ€§æ£€æµ‹ï¼ˆåªåœ¨æ­£è§†å›¾æ—¶ä½¿ç”¨ï¼Œä¾§è§†å›¾ä¸å‡†ç¡®ï¼‰
    if not is_aligned:  # æ­£é¢å¯¹é½æ—¶æ£€æµ‹å¯¹ç§°æ€§
        if shoulder_height_diff >= thresholds['shoulder']:
            issues.append('shoulder_tilt')
        if hip_height_diff >= thresholds['hip']:
            issues.append('hip_tilt')
        if head_tilt >= thresholds['head']:
            issues.append('head_tilt')
        if use_spinal_detection and spinal_curvature >= thresholds['spinal']:
            issues.append('spinal_curvature')
    
    # å¢å¼ºåˆ¤å®šï¼šä½¿ç”¨æ”¹è¿›çš„åŠ æƒè¯„åˆ†ç³»ç»Ÿ
    if USE_WEIGHTED_SCORING:
        # ä½¿ç”¨æ–°çš„æ¸è¿›å¼è¯„åˆ†ç®—æ³•
        # é‡è¦ï¼šå¯¹äºä¾§è§†å›¾æ•°æ®é›†ï¼Œä¸»è¦ä½¿ç”¨è§’åº¦æ£€æµ‹ï¼Œå¯¹ç§°æ€§æ£€æµ‹ä¸å‡†ç¡®
        if is_aligned:  # ä¾§é¢å¯¹é½ï¼Œä½¿ç”¨ä¾§é¢è¯„åˆ†ï¼ˆåªè€ƒè™‘è§’åº¦ï¼‰
            score_result = calculate_posture_score_side(
                {'neck_angle': neck_angle, 'torso_angle': torso_angle},
                {'neck': thresholds['neck'], 'torso': thresholds['torso']},
                is_sci_mode
            )
            # å¯¹äºä¾§è§†å›¾æ•°æ®é›†ï¼Œä½¿ç”¨æ›´ä¸¥æ ¼çš„è¯„åˆ†é˜ˆå€¼ï¼ˆ0.85ï¼‰ä»¥åŒ¹é…Basicæ¨¡å¼çš„ä¸¥æ ¼æ€§
            # Basicæ¨¡å¼è¦æ±‚ï¼šneck < 40 AND torso < 15ï¼ˆå…¨éƒ¨é€šè¿‡ï¼‰
            # Enhancedæ¨¡å¼ä½¿ç”¨åŠ æƒè¯„åˆ†ï¼Œä½†ä¸ºäº†åŒ¹é…Basicçš„ä¸¥æ ¼æ€§ï¼Œä½¿ç”¨æ›´é«˜çš„é˜ˆå€¼
            strict_threshold = 0.85 if not is_sci_mode else 0.75  # SCIæ¨¡å¼ç¨å®½æ¾
            is_good_enhanced = score_result['score'] >= strict_threshold
        else:  # æ­£é¢å¯¹é½ï¼Œä½¿ç”¨æ­£é¢è¯„åˆ†ï¼ˆè€ƒè™‘å¯¹ç§°æ€§ï¼‰
            # å¯¹äºæ­£è§†å›¾ï¼Œä½¿ç”¨å¯¹ç§°æ€§æ£€æµ‹
            spinal_metric = spinal_curvature if use_spinal_detection else None
            spinal_threshold = thresholds['spinal'] if use_spinal_detection else None
            
            score_result = calculate_posture_score_front(
                {
                    'shoulder_height_diff': shoulder_height_diff,
                    'hip_height_diff': hip_height_diff,
                    'head_tilt': head_tilt,
                    'spinal_curvature': spinal_metric
                },
                {
                    'shoulder': thresholds['shoulder'],
                    'hip': thresholds['hip'],
                    'head': thresholds['head'],
                    'spinal': spinal_threshold
                },
                is_sci_mode
            )
            is_good_enhanced = score_result['is_good']
    else:
        # å…¨éƒ¨é€šè¿‡æ‰ç®—è‰¯å¥½ï¼ˆä¸¥æ ¼æ¨¡å¼ï¼‰
        is_good_enhanced = len(issues) == 0
        score_result = {'score': 0, 'percentage': 0, 'breakdown': {}}
    
    # é€‰æ‹©ä½¿ç”¨å“ªä¸ªåˆ¤å®šç»“æœ
    if use_enhanced_detection:
        predicted_label = 'good' if is_good_enhanced else 'bad'
    else:
        predicted_label = 'good' if is_good_basic else 'bad'
    
    return {
        'neck_angle': neck_angle,
        'torso_angle': torso_angle,
        'shoulder_height_diff': shoulder_height_diff,
        'hip_height_diff': hip_height_diff,
        'head_tilt': head_tilt,
        'spinal_curvature': spinal_curvature,
        'spinal_direction': spinal_direction,
        'is_aligned': is_aligned,
        'predicted_label': predicted_label,
        'predicted_label_basic': 'good' if is_good_basic else 'bad',
        'landmarks_detected': True,
        'issues': issues,
        'score': score_result.get('score', 0),
        'score_percentage': score_result.get('percentage', 0),
        'score_breakdown': score_result.get('breakdown', {})
    }

def evaluate_dataset(data_dir='data', use_enhanced_detection=True, return_results=False, filter_view=None, threshold_mode='standard'):
    """
    è¯„ä¼°æ•´ä¸ªæ•°æ®é›†ï¼ˆæ”¯æŒåŸºç¡€ç‰ˆå’Œå¢å¼ºç‰ˆæ£€æµ‹ï¼‰
    
    Args:
        data_dir: æ•°æ®é›†æ ¹ç›®å½•
        use_enhanced_detection: æ˜¯å¦ä½¿ç”¨å¢å¼ºæ£€æµ‹ï¼ˆå¤šæŒ‡æ ‡ï¼‰
        return_results: æ˜¯å¦è¿”å›ç»“æœå­—å…¸ï¼ˆç”¨äºç»¼åˆæŠ¥å‘Šï¼‰
        filter_view: è¿‡æ»¤è§†è§’ç±»å‹ ('side', 'front', None=å…¨éƒ¨)
    """
    data_path = Path(data_dir)
    good_dir = data_path / 'good_posture'
    bad_dir = data_path / 'bad_posture'
    
    # Check if directories exist
    if not good_dir.exists():
        print(f"[ERROR] Error: {good_dir} directory does not exist")
        print("Please create data/good_posture/ directory and add good posture images")
        return
    
    if not bad_dir.exists():
        print(f"Error: {bad_dir} directory does not exist")
        print("Please create data/bad_posture/ directory and add bad posture images")
        return
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶ï¼ˆæ”¯æŒåµŒå¥—æ–‡ä»¶å¤¹ç»“æ„ï¼‰
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
    
    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰å›¾åƒæ–‡ä»¶ï¼ˆæ”¯æŒå­æ–‡ä»¶å¤¹ï¼‰
    def find_all_images(directory):
        """é€’å½’æŸ¥æ‰¾ç›®å½•ä¸‹æ‰€æœ‰å›¾åƒæ–‡ä»¶"""
        images = []
        for item in directory.iterdir():
            if item.is_file() and item.suffix.lower() in image_extensions:
                images.append(item)
            elif item.is_dir():
                # é€’å½’æŸ¥æ‰¾å­æ–‡ä»¶å¤¹
                images.extend(find_all_images(item))
        return images
    
    good_images = find_all_images(good_dir)
    bad_images = find_all_images(bad_dir)
    
    # Count samples (folders)
    good_folders = [d for d in good_dir.iterdir() if d.is_dir()]
    bad_folders = [d for d in bad_dir.iterdir() if d.is_dir()]
    
    print(f"\nDataset Statistics")
    print(f"{'='*70}")
    print(f"Good Posture:")
    print(f"  Number of samples (folders): {len(good_folders)}")
    print(f"  Total images: {len(good_images)}")
    if good_folders:
        avg_good = len(good_images) / len(good_folders)
        print(f"  Average per sample: {avg_good:.1f} images")
    print(f"\nBad Posture:")
    print(f"  Number of samples (folders): {len(bad_folders)}")
    print(f"  Total images: {len(bad_images)}")
    if bad_folders:
        avg_bad = len(bad_images) / len(bad_folders)
        print(f"  Average per sample: {avg_bad:.1f} images")
    print(f"\nTotal: {len(good_images) + len(bad_images)} images")
    
    if len(good_images) == 0 and len(bad_images) == 0:
        print("\n[ERROR] Dataset is empty! Please add image files.")
        return
    
    # Process all images
    print(f"\nStarting evaluation...")
    print(f"{'='*70}")
    
    y_true = []  # True labels
    y_pred = []  # Predicted labels
    results = []
    
    # Process good posture images
    detection_mode = "Enhanced" if use_enhanced_detection else "Basic"
    mode_note = f" [{threshold_mode}]" if threshold_mode != 'standard' else ""
    view_filter_note = f", {filter_view} view only" if filter_view else ""
    print(f"\nProcessing good posture images ({detection_mode} mode{mode_note}{view_filter_note})...")
    processed = 0
    for img_path in good_images:
        result = analyze_image(img_path, use_enhanced_detection, detect_view=(filter_view is not None), threshold_mode=threshold_mode)
        if result and result['landmarks_detected']:
            y_true.append('good')
            y_pred.append(result['predicted_label'])
            results.append({
                'image': img_path.name,
                'true_label': 'good',
                'predicted_label': result['predicted_label'],
                'predicted_label_basic': result.get('predicted_label_basic', result['predicted_label']),
                'neck_angle': result['neck_angle'],
                'torso_angle': result['torso_angle'],
                'shoulder_height_diff': result.get('shoulder_height_diff', 0),
                'hip_height_diff': result.get('hip_height_diff', 0),
                'head_tilt': result.get('head_tilt', 0),
                'is_aligned': result['is_aligned'],
                'issues': result.get('issues', [])
            })
            processed += 1
            if processed % 50 == 0:
                print(f"  Processed {processed}/{len(good_images)} images...")
        elif result and not result['landmarks_detected']:
            print(f"  Warning: {img_path.name}: No landmarks detected")
    
    # Process bad posture images
    print(f"\nProcessing bad posture images ({detection_mode} mode{mode_note}{view_filter_note})...")
    processed = 0
    for img_path in bad_images:
        result = analyze_image(img_path, use_enhanced_detection, detect_view=(filter_view is not None), threshold_mode=threshold_mode)
        
        # å¦‚æœæŒ‡å®šäº†è§†è§’è¿‡æ»¤ï¼Œè·³è¿‡ä¸ç¬¦åˆçš„å›¾åƒ
        if filter_view and result and result.get('view_type') != filter_view:
            continue
        if result and result['landmarks_detected']:
            y_true.append('bad')
            y_pred.append(result['predicted_label'])
            results.append({
                'image': img_path.name,
                'true_label': 'bad',
                'predicted_label': result['predicted_label'],
                'predicted_label_basic': result.get('predicted_label_basic', result['predicted_label']),
                'neck_angle': result['neck_angle'],
                'torso_angle': result['torso_angle'],
                'shoulder_height_diff': result.get('shoulder_height_diff', 0),
                'hip_height_diff': result.get('hip_height_diff', 0),
                'head_tilt': result.get('head_tilt', 0),
                'is_aligned': result['is_aligned'],
                'issues': result.get('issues', [])
            })
            processed += 1
            if processed % 50 == 0:
                print(f"  Processed {processed}/{len(bad_images)} images...")
        elif result and not result['landmarks_detected']:
            print(f"  Warning: {img_path.name}: No landmarks detected")
    
    if len(y_true) == 0:
        print("\nError: No images were successfully processed! Please check image format and content.")
        return
    
    # Convert to numeric labels (for sklearn)
    label_map = {'good': 1, 'bad': 0}
    y_true_numeric = [label_map[label] for label in y_true]
    y_pred_numeric = [label_map[label] for label in y_pred]
    
    # Calculate metrics for each class
    # Use sklearn's classification_report for accurate per-class metrics
    from sklearn.metrics import classification_report
    
    # Get classification report as dict
    report_dict = classification_report(
        y_true_numeric, 
        y_pred_numeric, 
        target_names=['bad', 'good'],
        output_dict=True,
        zero_division=0
    )
    
    # Extract metrics
    precision_good = report_dict['good']['precision']
    recall_good = report_dict['good']['recall']
    f1_good = report_dict['good']['f1-score']
    support_good = int(report_dict['good']['support'])
    
    precision_bad = report_dict['bad']['precision']
    recall_bad = report_dict['bad']['recall']
    f1_bad = report_dict['bad']['f1-score']
    support_bad = int(report_dict['bad']['support'])
    
    # Confusion matrix
    cm = confusion_matrix(y_true_numeric, y_pred_numeric)
    # cm format for labels [0, 1]: [[TN, FP], [FN, TP]]
    TN, FP = cm[0][0], cm[0][1]
    FN, TP = cm[1][0], cm[1][1]
    
    # Overall metrics from report
    accuracy = report_dict['accuracy']
    total_samples = len(y_true)
    
    # Macro and weighted averages from report (more accurate)
    macro_precision = report_dict['macro avg']['precision']
    macro_recall = report_dict['macro avg']['recall']
    macro_f1 = report_dict['macro avg']['f1-score']
    
    weighted_precision = report_dict['weighted avg']['precision']
    weighted_recall = report_dict['weighted avg']['recall']
    weighted_f1 = report_dict['weighted avg']['f1-score']
    
    # Print detailed report - matching the format in the image
    print("\n" + "="*70)
    print("Detailed Report:")
    print("="*70)
    # Header row
    print(f"{'':<12} {'precision':<12} {'recall':<12} {'f1-score':<12} {'support':<12}")
    print("-"*70)
    # Class rows
    print(f"{'good':<12} {precision_good:<12.2f} {recall_good:<12.2f} {f1_good:<12.2f} {support_good:<12}")
    print(f"{'bad':<12} {precision_bad:<12.2f} {recall_bad:<12.2f} {f1_bad:<12.2f} {support_bad:<12}")
    print("-"*70)
    # Accuracy row (no recall/f1 for accuracy)
    print(f"{'accuracy':<12} {accuracy:<12.2f} {'':<12} {'':<12} {total_samples:<12}")
    # Macro average
    print(f"{'macro avg':<12} {macro_precision:<12.2f} {macro_recall:<12.2f} {macro_f1:<12.2f} {total_samples:<12}")
    # Weighted average
    print(f"{'weighted avg':<12} {weighted_precision:<12.2f} {weighted_recall:<12.2f} {weighted_f1:<12.2f} {total_samples:<12}")
    
    # Confusion Matrix - matching the format in the image
    print("\n" + "="*70)
    print("Confusion Matrix:")
    print("="*70)
    # Header row
    print(f"{'':<25} {'Predicted good':<20} {'Predicted bad':<20}")
    print("-"*70)
    # Actual rows
    print(f"{'Actual good':<25} {TP:<20} {FN:<20}")
    print(f"{'Actual bad':<25} {FP:<20} {TN:<20}")
    
    # Additional statistics for enhanced detection
    if use_enhanced_detection:
        print("\n" + "="*70)
        print("Enhanced Detection Statistics:")
        print("="*70)
        
        # Count issues
        issue_counts = {}
        for r in results:
            for issue in r.get('issues', []):
                issue_counts[issue] = issue_counts.get(issue, 0) + 1
        
        if issue_counts:
            print("\nIssue Distribution:")
            for issue, count in sorted(issue_counts.items(), key=lambda x: x[1], reverse=True):
                print(f"  {issue}: {count} images")
        
        # æ˜¾ç¤ºè¯„åˆ†ç»Ÿè®¡
        if results and any(r.get('score_percentage') is not None for r in results):
            scores = [r.get('score_percentage', 0) for r in results if r.get('score_percentage') is not None]
            if scores:
                avg_score = sum(scores) / len(scores)
                print(f"\nScore Statistics:")
                print(f"  Average score: {avg_score:.1f}%")
                print(f"  Min score: {min(scores)}%")
                print(f"  Max score: {max(scores)}%")
        
        # Compare with basic detection
        basic_correct = sum(1 for r in results if r['true_label'] == r['predicted_label_basic'])
        enhanced_correct = sum(1 for r in results if r['true_label'] == r['predicted_label'])
        
        print(f"\nComparison with Basic Detection:")
        print(f"  Basic accuracy: {basic_correct/len(results)*100:.2f}% ({basic_correct}/{len(results)})")
        print(f"  Enhanced accuracy: {enhanced_correct/len(results)*100:.2f}% ({enhanced_correct}/{len(results)})")
        improvement = enhanced_correct - basic_correct
        if improvement > 0:
            print(f"  Improvement: +{improvement} images ({improvement/len(results)*100:.2f}%)")
        elif improvement < 0:
            print(f"  Change: {improvement} images ({improvement/len(results)*100:.2f}%)")
        else:
            print(f"  No change")
    
    # Final summary with checkmark
    print("\n" + "="*70)
    print("Evaluation Complete! âœ“")
    print("="*70)
    
    # Quick summary at the end (optional, can be removed if too verbose)
    print(f"\nğŸ“Š Quick Summary:")
    print(f"   Total Samples: {total_samples}")
    print(f"   Overall Accuracy: {accuracy*100:.2f}%")
    print(f"   Good Class: Precision={precision_good:.2f}, Recall={recall_good:.2f}, F1={f1_good:.2f}")
    print(f"   Bad Class: Precision={precision_bad:.2f}, Recall={recall_bad:.2f}, F1={f1_bad:.2f}")
    print(f"   Confusion: TP={TP}, TN={TN}, FP={FP}, FN={FN}")
    print("="*70)
    
    # Return results if requested
    if return_results:
        return {
            'accuracy': accuracy,
            'precision_good': precision_good,
            'recall_good': recall_good,
            'f1_good': f1_good,
            'precision_bad': precision_bad,
            'recall_bad': recall_bad,
            'f1_bad': f1_bad,
            'f1_macro': macro_f1,
            'total_samples': total_samples,
            'mode': 'enhanced' if use_enhanced_detection else 'basic'
        }

def generate_comprehensive_report():
    """
    ç”Ÿæˆç»¼åˆæŠ¥å‘Šï¼šåŒæ—¶è¿è¡ŒåŸºç¡€æ£€æµ‹å’Œå¢å¼ºæ£€æµ‹ï¼Œå¹¶ç”Ÿæˆåˆå¹¶æŠ¥å‘Š
    """
    print("="*70)
    print("COMPREHENSIVE EVALUATION REPORT")
    print("="*70)
    print("\nThis report evaluates both detection modes:")
    print("1. Basic Detection (Side View): Neck + Torso angles")
    print("2. Enhanced Detection (Front View): Multiple indicators")
    print("\nNote: Current dataset contains side-view images only.")
    print("Enhanced detection results may be less accurate for side-view data.\n")
    
    # Run basic detection
    print("\n" + "="*70)
    print("PART 1: BASIC DETECTION (Side View Mode)")
    print("="*70)
    print("Detection: Neck angle + Torso angle")
    print("Recommended for: Side-view images (current dataset)")
    print("-"*70)
    
    basic_results = evaluate_dataset(use_enhanced_detection=False, return_results=True)
    
    # Run enhanced detection
    print("\n\n" + "="*70)
    print("PART 2: ENHANCED DETECTION (Front View Mode)")
    print("="*70)
    print("Detection: Neck + Torso + Shoulder + Hip + Head")
    print("Recommended for: Front-view images")
    print("Note: Current dataset is side-view, results may be less accurate")
    print("-"*70)
    
    enhanced_results = evaluate_dataset(use_enhanced_detection=True, return_results=True)
    
    # Summary comparison
    print("\n\n" + "="*70)
    print("SUMMARY COMPARISON")
    print("="*70)
    
    if basic_results and enhanced_results:
        print(f"\n{'Metric':<25} {'Basic (Side)':<20} {'Enhanced (Front)':<20}")
        print("-"*70)
        print(f"{'Accuracy':<25} {basic_results['accuracy']*100:<19.2f}% {enhanced_results['accuracy']*100:<19.2f}%")
        print(f"{'Good Precision':<25} {basic_results['precision_good']:<20.2f} {enhanced_results['precision_good']:<20.2f}")
        print(f"{'Good Recall':<25} {basic_results['recall_good']:<20.2f} {enhanced_results['recall_good']:<20.2f}")
        print(f"{'Bad Precision':<25} {basic_results['precision_bad']:<20.2f} {enhanced_results['precision_bad']:<20.2f}")
        print(f"{'Bad Recall':<25} {basic_results['recall_bad']:<20.2f} {enhanced_results['recall_bad']:<20.2f}")
        print(f"{'F1-Score (Macro)':<25} {basic_results['f1_macro']:<20.2f} {enhanced_results['f1_macro']:<20.2f}")
        
        print("\n" + "-"*70)
        print("RECOMMENDATION:")
        if basic_results['accuracy'] > enhanced_results['accuracy']:
            print(f"-> Use BASIC detection for current dataset (side-view images)")
            print(f"   Accuracy: {basic_results['accuracy']*100:.2f}% vs {enhanced_results['accuracy']*100:.2f}%")
        else:
            print(f"-> Enhanced detection shows better results")
        
        print("\n" + "-"*70)
        print("FOR YOUR WEBSITE:")
        print("-> Side view detected: Use BASIC detection (Part 1 results)")
        print("-> Front view detected: Use ENHANCED detection (Part 2 results)")
        print("-> System automatically switches based on camera angle")
    
    print("\n" + "="*70)
    print("COMPREHENSIVE EVALUATION COMPLETE!")
    print("="*70)

if __name__ == "__main__":
    import sys
    
    # Parse command line arguments
    use_enhanced = True  # Default to enhanced detection
    threshold_mode = 'standard'  # Default threshold mode
    
    if len(sys.argv) > 1:
        if sys.argv[1] == '--basic':
            use_enhanced = False
            print("Using BASIC detection (neck + torso angles only)\n")
        elif sys.argv[1] == '--enhanced':
            use_enhanced = True
            print("Using ENHANCED detection (multiple indicators)\n")
        elif sys.argv[1] == '--sci-relaxed':
            threshold_mode = 'sciRelaxed'
            print("Using SCI RELAXED mode (for early rehabilitation/severe patients)\n")
        elif sys.argv[1] == '--sci-strict':
            threshold_mode = 'sciStrict'
            print("Using SCI STRICT mode (for late rehabilitation/mild patients)\n")
        elif sys.argv[1] == '--compare':
            # Compare both modes
            print("="*70)
            print("BASIC Detection Mode (Neck + Torso angles only)")
            print("="*70)
            evaluate_dataset(use_enhanced_detection=False)
            
            print("\n\n" + "="*70)
            print("ENHANCED Detection Mode (Multiple indicators)")
            print("="*70)
            evaluate_dataset(use_enhanced_detection=True)
            sys.exit(0)
        elif sys.argv[1] == '--comprehensive' or sys.argv[1] == '--full':
            # Generate comprehensive report
            generate_comprehensive_report()
            sys.exit(0)
        elif sys.argv[1] == '--compare-modes':
            # Compare all threshold modes
            print("="*70)
            print("COMPARING ALL THRESHOLD MODES")
            print("="*70)
            for mode in ['standard', 'sciRelaxed', 'sciStrict']:
                print(f"\n\n{'='*70}")
                print(f"Mode: {mode.upper()}")
                print("="*70)
                evaluate_dataset(use_enhanced_detection=True, threshold_mode=mode)
            sys.exit(0)
    
    if use_enhanced:
        mode_desc = {
            'standard': 'Standard mode (healthy people)',
            'sciRelaxed': 'SCI Relaxed mode (early rehabilitation)',
            'sciStrict': 'SCI Strict mode (late rehabilitation)'
        }
        print(f"Using ENHANCED detection mode with {mode_desc.get(threshold_mode, 'standard')}")
        print("Use --basic for basic mode, --compare to compare both modes")
        print("Use --sci-relaxed for SCI relaxed mode, --sci-strict for SCI strict mode")
        print("Use --compare-modes to compare all threshold modes")
        print("Use --comprehensive for full report with both modes\n")
    
    evaluate_dataset(use_enhanced_detection=use_enhanced, threshold_mode=threshold_mode)

